# Modèle pour le fichier de conf .env à ajouter à la racine
# du projet. Le fichier est lu directement par
# docker-compose

# Nom du compose project
# Permet de faire tourner plusieurs containers
# du même type sur une même machine
# (preprod et prod par exemple)
COMPOSE_PROJECT_NAME=kelrisks-data-preparation-dev

# Port sur lequel le serveur Airflow démarre
AIRFLOW__WEBSERVER__WEB_SERVER_PORT=8080

# Nombre de worker Gunicorn du serveur Airflow
AIRFLOW__WEBSERVER__WORKERS=4

# La variable AIRFLOW__WEBSERVER__WEB_SERVER_HOST
# est utilisé en preprd et prod uniquement
# Elle sert à limiter l'accès au serveur Airflow
# Il est recommandé de fixer cette valeur à 127.0.0.1
# pour autoriser uniquement les requêtes depuis localhost
# et d'utiliser un tunnel ssh pour accéder au serveur
AIRFLOW__WEBSERVER__WEB_SERVER_HOST=127.0.0.1

# Clé utilisée par Airflow pour encrypter
# les mots de passe des connections
# Voir https://bcb.github.io/airflow/fernet-key
AIRFLOW__CORE__FERNET_KEY=********

# Nombre de tâches que le scheduler Airflow
# peut faire tourner en parallèle. Attention à
# ne pas fixer ce nombre trop haut pour charger
# les données du cadastre, car ça peut vite
# prendre pas mal de mémoire. Typiquement en preprod
# avec 4Go de RAM pour tous les services, il ne faudra
# pas dépasser 1 ou 2
AIRFLOW__CORE__DAG_CONCURRENCY=4

# Informations de connexion utilisées par
# Airflow comme backend.
#
# Dans le cas de l'utilisation de docker-compose.dev.yml
# il faut utiliser `postgres` comme hôte postgres. Les autres
# infos de connexion vont servir à créer automatiquement
# l'utilisateur et la base de données airflow lors
# de la première création du container
#
# Dans le cas de l'utilisation de docker-compose.dev.airflow-only.yml
# avec une base postgres existante sur localhost il faut utiliser `host.docker.internal`
# comme hôte postgres (Mac et Windows uniquement).
# Il sera nécessaire de créer l'utilisateur et la base airflow à la main au préalable.
AIRFLOW_POSTGRES_HOST=postgres
AIRFLOW_POSTGRES_PORT=5432
AIRFLOW_POSTGRES_USER=airflow
AIRFLOW_POSTGRES_PASSWORD=********
AIRFLOW_POSTGRES_DB=airflow

# Informations de connexion pour les données kelrisks
# (schéma kelrisks et etl).
#
# Dans le cas de l'utilisation de docker-compose.dev.yml
# Il faut utiliser `postgres` comme hôte postgres. Les autres
# infos de connexion vont servir à créer automatiquement
# l'utilisateur et la base de données kelrisks lors de la
# première création du container
#
# Dans le cas de l'utilisation de docker-compose.dev.airflow-only.yml
# avec une base postgres existante sur localhost, il faut utiliser
# `host.docker.internal` comme hôte postgres (Mac et Windows uniquement).
# Il faudra reporter dans les infos de connexion à la database kelrisks
# existante ici et créer un schéma `etl`
KELRISKS_POSTGRES_DB=kelrisks
KELRISKS_POSTGRES_HOST=********
KELRISKS_POSTGRES_USER=kelrisks
KELRISKS_POSTGRES_PASSWORD=********
KELRISKS_POSTGRES_PORT=5432
KELRISKS_POSTGRES_SSL_ON=False

# Cette variable est utilisée pour limiter la préparation des données
# à un certain nombre de départemnents. C'est utile en local pour ne
# pas avoir à charger toute la table cadastre (~50Go). On se limitera
# typiquement à un ou deux départements. Pour prendre en compte
# tous les départements français, il faut fixer cette valeur à `all`
DEPARTEMENTS=93,07

# La variable BRANCH est utilisée en preprod et prod uniquement
# Elle sert à spécifier la branche Github qui est synchronisée
# avec l'environnement courant et le nom de l'image docker à télécharger.
# On a la correspondance suivante
# preprod <=> branche `dev`
# prod <=> branche `master`
BRANCH=dev


